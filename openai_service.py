import os
import logging
import random
from datetime import datetime, timedelta
try:
    from openai import OpenAI
except ImportError:
    logging.error("OpenAI package not installed. Please install it with 'pip install openai'.")
    OpenAI = None

# OpenAI API key
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# Initialize OpenAI client
openai = OpenAI(api_key=OPENAI_API_KEY)

# Setup logging
logger = logging.getLogger(__name__)

# 1. AgentIntentRecognizer: æ„åœ–è­˜åˆ¥å™¨
def recognize_intent(user_message):
    """
    åˆ¤æ–·ä½¿ç”¨è€…è¨Šæ¯å±¬æ–¼ï¼š
    - "chat"ï¼šä¸€èˆ¬é–’èŠ/å¯’æš„
    - "professional"ï¼šå°ˆæ¥­å•é¡Œ/éœ€ä¾æ“šæ¨™æº–å›ç­”
    """
    chat_keywords = ["ä½ å¥½", "è¬è¬", "åœ¨å—", "å“ˆå›‰", "è«‹å•åœ¨å—", "ä»Šå¤©å¥½å—", "åŠ æ²¹", "è¾›è‹¦äº†"]
    professional_keywords = ["ç¢³ç›¤æŸ¥", "ç¢³è¶³è·¡", "ç¢³ä¸­å’Œ", "ISO14064", "SBTi", "ç’°å¢ƒéƒ¨", "æŸ¥è­‰", 
                           "æ¸›é‡å°ˆæ¡ˆ", "æ’æ”¾", "æº«å®¤æ°£é«”", "ESG", "æ°¸çºŒ", "æ·¨é›¶", "ç¢³", "æ’ç¢³", 
                           "æ¸›ç¢³", "å ±å‘Š", "æ­éœ²", "æ¨™æº–", "è¦ç¯„", "ç›¤æŸ¥"]

    if any(word in user_message for word in chat_keywords) and not any(word in user_message for word in professional_keywords):
        return "chat"
    else:
        # ä¿å®ˆç­–ç•¥ï¼ŒæœªçŸ¥é è¨­ç‚ºå°ˆæ¥­å•é¡Œï¼ˆé¿å…æ¼æ‰æ­£ç¶“å•é¡Œï¼‰
        return "professional"

# 2. AgentClassifier: å•é¡Œåˆ†é¡å™¨
def classify_question(user_message):
    """
    åˆ†æä½¿ç”¨è€…è¨Šæ¯ï¼Œåˆ†é¡è‡³é©ç•¶çš„ ESG çŸ¥è­˜ç¯„åœã€‚
    å›å‚³ç¯„åœæ¨™ç±¤ï¼Œä¾‹å¦‚ "ISO14064-1"ã€"SBTi"ã€"WBCSD"ã€‚
    """
    # é—œéµå­—åˆ†é¡é‚è¼¯
    if any(word in user_message for word in ["ç›¤æŸ¥", "çµ„ç¹”ç¢³æ’", "çµ„ç¹”ç¢³ç›¤æŸ¥", "ç¯„ç–‡ä¸€", "ç¯„ç–‡äºŒ", "ç¯„ç–‡ä¸‰"]):
        return "ISO14064-1"
    elif any(word in user_message for word in ["æ¸›é‡å°ˆæ¡ˆ", "æ¸›ç¢³å°ˆæ¡ˆ", "ç¢³æ¬Š", "æŠµæ¸›", "ç¢³è£œå„Ÿ", "æ¸›ç¢³æ–¹æ³•"]):
        return "ISO14064-2"
    elif any(word in user_message for word in ["æŸ¥è­‰", "ç¬¬ä¸‰æ–¹æŸ¥æ ¸", "ç¢ºä¿¡", "ä¿è­‰", "é©—è­‰"]):
        return "ISO14064-3"
    elif any(word in user_message for word in ["ç¢³è¶³è·¡", "ç”¢å“ç¢³æ’", "PCF", "LCA", "ç”Ÿå‘½é€±æœŸ", "CFP"]):
        return "ISO14067"
    elif any(word in user_message for word in ["ç¢³ä¸­å’Œ", "æ·¨é›¶", "ç¢³ç§»é™¤", "carbon neutral", "net zero"]):
        return "ISO14068-1"
    elif any(word in user_message for word in ["SBTi", "ç§‘å­¸åŸºç¤ç›®æ¨™", "ç§‘å­¸åŸºç¤æ¸›ç¢³"]):
        return "SBTi"
    elif any(word in user_message for word in ["ä¼æ¥­ç­–ç•¥", "æ°¸çºŒç­–ç•¥", "ä¼æ¥­æ°¸çºŒ", "ESG", "WBCSD"]):
        return "WBCSD"
    elif any(word in user_message for word in ["å°ç£", "ç’°å¢ƒéƒ¨", "æ³•è¦", "ç®¡åˆ¶", "ç”³å ±"]):
        return "TaiwanReg"
    else:
        return "General"

# 3. AgentKnowledgeAssembler: çŸ¥è­˜æ•´åˆå™¨
def build_knowledge_prompt(category):
    """
    æ ¹æ“šåˆ†é¡çµæœï¼Œçµ„åˆå°ˆæ¥­èƒŒæ™¯å…§å®¹ï¼Œé™åˆ¶å›è¦†åªä¾æ“šç‰¹å®šæ¨™æº–ã€‚
    """
    base_prompt = """ä½ æ˜¯ä¸€ä½ç¶“é©—è±å¯Œã€ç«‹å ´å‹™å¯¦çš„ ESG é¡§å•ï¼Œç†Ÿæ‚‰ç¢³ç›¤æŸ¥åˆ¶åº¦ã€ä»¥åŠç›¸é—œåœ‹éš›è¦ç¯„ã€‚ä½ çš„å›ç­”åªèƒ½åŸºæ–¼ç‰¹å®šçŸ¥è­˜ç¯„åœï¼Œä¸å¯è‡†æ¸¬æˆ–å¼•ç”¨è¶…å‡ºç¯„åœçš„è³‡è¨Šã€‚"""
    
    if category == "ISO14064-1":
        knowledge = """
ä½ æ‡‰è©²åªå¼•ç”¨ ISO14064-1ï¼ˆçµ„ç¹”å±¤ç´šæº«å®¤æ°£é«”æ’æ”¾é‡åŒ–èˆ‡å ±å‘Šï¼‰æ¨™æº–æä¾›å›ç­”ï¼Œç›¸é—œé‡é»åŒ…æ‹¬ï¼š
1. æ¸…å†Šé‚Šç•ŒåŠƒå®šï¼ˆç‡Ÿé‹æ§åˆ¶æ¬Š/è²¡å‹™æ§åˆ¶æ¬Š/è‚¡æ¬Šï¼‰
2. ç¯„ç–‡ä¸€/äºŒ/ä¸‰æ’æ”¾æºè¾¨è­˜èˆ‡è¨ˆç®—æ–¹æ³•
3. ä¸ƒç¨®æº«å®¤æ°£é«”ï¼ˆCO2/CH4/N2O/HFCs/PFCs/SF6/NF3ï¼‰çš„é‡åŒ–è¦æ±‚
4. ç›¤æŸ¥åŸºæº–å¹´ï¼ˆBase Yearï¼‰é¸æ“‡èˆ‡ç®¡ç†
5. æ•¸æ“šå“è³ªèˆ‡æ–‡ä»¶ç®¡ç†
6. ä¸ç¢ºå®šæ€§è©•ä¼°

è«‹å‹™å¿…æŒ‡å‡ºé€™æ˜¯ä¾æ“šISO14064-1æ¨™æº–æä¾›çš„å»ºè­°ï¼Œè‹¥æœ‰å…¶ä»–æ¨™æº–åƒè€ƒï¼Œå¿…é ˆæ˜ç¢ºæ¨™ç¤ºã€‚è‹¥ä½¿ç”¨è€…æå•è¶…å‡ºæ¨™æº–ç¯„åœï¼Œè«‹èª å¯¦èªªæ˜ä¸¦æä¾›ä¸€èˆ¬æ€§å»ºè­°ã€‚
"""
    elif category == "ISO14064-2":
        knowledge = """
ä½ æ‡‰è©²åªå¼•ç”¨ ISO14064-2ï¼ˆå°ˆæ¡ˆå±¤ç´šæº«å®¤æ°£é«”æ¸›é‡é‡åŒ–èˆ‡ç›£æ¸¬ï¼‰æ¨™æº–æä¾›å›ç­”ï¼Œç›¸é—œé‡é»åŒ…æ‹¬ï¼š
1. æ¸›é‡å°ˆæ¡ˆè¨­è¨ˆèˆ‡æ–¹æ³•å­¸é¸æ“‡
2. åŸºç·šæƒ…å¢ƒï¼ˆBaseline scenarioï¼‰å»ºç«‹
3. å°ˆæ¡ˆæƒ…å¢ƒé‚Šç•Œèˆ‡æ’æ”¾æºè¾¨è­˜
4. é¡å¤–æ€§ï¼ˆAdditionalityï¼‰è­‰æ˜
5. æ¸›é‡æˆæ•ˆç›£æ¸¬èˆ‡é‡åŒ–
6. å°ˆæ¡ˆæ–‡ä»¶è£½ä½œèˆ‡ç¬¬ä¸‰æ–¹æŸ¥è­‰è¦æ±‚

è«‹å‹™å¿…æŒ‡å‡ºé€™æ˜¯ä¾æ“šISO14064-2æ¨™æº–æä¾›çš„å»ºè­°ï¼Œè‹¥æœ‰å…¶ä»–æ¨™æº–åƒè€ƒï¼Œå¿…é ˆæ˜ç¢ºæ¨™ç¤ºã€‚è‹¥ä½¿ç”¨è€…æå•è¶…å‡ºæ¨™æº–ç¯„åœï¼Œè«‹èª å¯¦èªªæ˜ä¸¦æä¾›ä¸€èˆ¬æ€§å»ºè­°ã€‚
"""
    elif category == "ISO14064-3":
        knowledge = """
ä½ æ‡‰è©²åªå¼•ç”¨ ISO14064-3ï¼ˆæº«å®¤æ°£é«”æŸ¥è­‰èˆ‡ç¢ºè­‰ï¼‰æ¨™æº–æä¾›å›ç­”ï¼Œç›¸é—œé‡é»åŒ…æ‹¬ï¼š
1. æŸ¥è­‰/ç¢ºè­‰æµç¨‹èˆ‡åŸå‰‡
2. æŸ¥è­‰åœ˜éšŠçµ„æˆèˆ‡èƒ½åŠ›è¦æ±‚
3. ä¿è­‰ç­‰ç´šï¼ˆåˆç†/æœ‰é™ï¼‰é¸æ“‡
4. ä¸ç¬¦åˆäº‹é …åˆ†ç´šèˆ‡è™•ç†
5. é‡å¤§æ€§ï¼ˆMaterialityï¼‰è©•ä¼°
6. æŸ¥è­‰å ±å‘Šèˆ‡è²æ˜æ›¸è£½ä½œ

è«‹å‹™å¿…æŒ‡å‡ºé€™æ˜¯ä¾æ“šISO14064-3æ¨™æº–æä¾›çš„å»ºè­°ï¼Œè‹¥æœ‰å…¶ä»–æ¨™æº–åƒè€ƒï¼Œå¿…é ˆæ˜ç¢ºæ¨™ç¤ºã€‚è‹¥ä½¿ç”¨è€…æå•è¶…å‡ºæ¨™æº–ç¯„åœï¼Œè«‹èª å¯¦èªªæ˜ä¸¦æä¾›ä¸€èˆ¬æ€§å»ºè­°ã€‚
"""
    elif category == "ISO14067":
        knowledge = """
ä½ æ‡‰è©²åªå¼•ç”¨ ISO14067ï¼ˆç”¢å“ç¢³è¶³è·¡ï¼‰æ¨™æº–æä¾›å›ç­”ï¼Œç›¸é—œé‡é»åŒ…æ‹¬ï¼š
1. ç”¢å“ç³»çµ±é‚Šç•Œå®šç¾©
2. åŠŸèƒ½å–®ä½ï¼ˆFunctional unitï¼‰é¸æ“‡
3. ç”Ÿå‘½é€±æœŸç›¤æŸ¥èˆ‡æ•¸æ“šæ”¶é›†
4. åˆ†é…ï¼ˆAllocationï¼‰æ–¹æ³•
5. å„éšæ®µæ´»å‹•æ•¸æ“šèˆ‡æ’æ”¾ä¿‚æ•¸é¸ç”¨
6. ç”¢å“ç¢³è¶³è·¡æ¨™ç¤ºèˆ‡å®£å‘Šè¦æ±‚

è«‹å‹™å¿…æŒ‡å‡ºé€™æ˜¯ä¾æ“šISO14067æ¨™æº–æä¾›çš„å»ºè­°ï¼Œè‹¥æœ‰å…¶ä»–æ¨™æº–åƒè€ƒï¼Œå¿…é ˆæ˜ç¢ºæ¨™ç¤ºã€‚è‹¥ä½¿ç”¨è€…æå•è¶…å‡ºæ¨™æº–ç¯„åœï¼Œè«‹èª å¯¦èªªæ˜ä¸¦æä¾›ä¸€èˆ¬æ€§å»ºè­°ã€‚
"""
    elif category == "ISO14068-1":
        knowledge = """
ä½ æ‡‰è©²åªå¼•ç”¨ ISO14068-1ï¼ˆç¢³ä¸­å’Œï¼‰æ¨™æº–æä¾›å›ç­”ï¼Œç›¸é—œé‡é»åŒ…æ‹¬ï¼š
1. ç¢³ä¸­å’Œï¼ˆCarbon Neutralityï¼‰å®šç¾©èˆ‡ç¯„åœ
2. ç§»é™¤/æŠµæ¸›æ–¹æ³•é¸æ“‡èˆ‡è©•ä¼°
3. ç¢³ä¸­å’Œä¸»å¼µèˆ‡å®£å‘Šè¦ç¯„
4. ç¢³ä¸­å’Œè¨ˆç•«åˆ¶å®šèˆ‡å¯¦æ–½
5. æŠµæ¸›æ©Ÿåˆ¶é¸æ“‡æ¨™æº–
6. ç¢³ä¸­å’Œé€²åº¦è¿½è¹¤èˆ‡å ±å‘Š

è«‹å‹™å¿…æŒ‡å‡ºé€™æ˜¯ä¾æ“šISO14068-1æ¨™æº–æä¾›çš„å»ºè­°ï¼Œè‹¥æœ‰å…¶ä»–æ¨™æº–åƒè€ƒï¼Œå¿…é ˆæ˜ç¢ºæ¨™ç¤ºã€‚è‹¥ä½¿ç”¨è€…æå•è¶…å‡ºæ¨™æº–ç¯„åœï¼Œè«‹èª å¯¦èªªæ˜ä¸¦æä¾›ä¸€èˆ¬æ€§å»ºè­°ã€‚
"""
    elif category == "SBTi":
        knowledge = """
ä½ æ‡‰è©²åªå¼•ç”¨ SBTiï¼ˆç§‘å­¸åŸºç¤æ¸›ç¢³ç›®æ¨™å€¡è­°ï¼‰æŒ‡å¼•æä¾›å›ç­”ï¼Œç›¸é—œé‡é»åŒ…æ‹¬ï¼š
1. è¿‘æœŸèˆ‡é•·æœŸæ¸›ç¢³ç›®æ¨™è¨­å®šï¼ˆè¿‘æœŸ/é•·æœŸï¼‰
2. ç›®æ¨™å¯©æ ¸èˆ‡æäº¤æµç¨‹
3. Flagæ¨¡å‹/SDAæ¨¡å‹/ABSæ¨¡å‹é¸æ“‡
4. æ°£å€™è®Šé·æƒ…å¢ƒå°é½Šï¼ˆ1.5Â°C/well-below 2Â°Cï¼‰
5. ç¯„ç–‡ä¸‰ç´å…¥è¦æ±‚èˆ‡è¨ˆç®—
6. ç›®æ¨™è¿½è¹¤èˆ‡æ›´æ–°æ©Ÿåˆ¶
7. æ·¨é›¶æ‰¿è«¾èˆ‡è·¯å¾‘è¦åŠƒ

è«‹å‹™å¿…æŒ‡å‡ºé€™æ˜¯ä¾æ“šSBTiæ¨™æº–æä¾›çš„å»ºè­°ï¼Œè‹¥æœ‰å…¶ä»–æ¨™æº–åƒè€ƒï¼Œå¿…é ˆæ˜ç¢ºæ¨™ç¤ºã€‚è‹¥ä½¿ç”¨è€…æå•è¶…å‡ºæ¨™æº–ç¯„åœï¼Œè«‹èª å¯¦èªªæ˜ä¸¦æä¾›ä¸€èˆ¬æ€§å»ºè­°ã€‚
"""
    elif category == "WBCSD":
        knowledge = """
ä½ æ‡‰è©²åªå¼•ç”¨ WBCSDï¼ˆä¸–ç•Œä¼æ¥­æ°¸çºŒç™¼å±•å§”å“¡æœƒï¼‰æŒ‡å—æä¾›å›ç­”ï¼Œç›¸é—œé‡é»åŒ…æ‹¬ï¼š
1. ä¼æ¥­æ°¸çºŒç­–ç•¥èˆ‡æ•´åˆ
2. æ°¸çºŒå ±å‘Šèˆ‡æ­éœ²æ¡†æ¶
3. åƒ¹å€¼éˆåˆä½œèˆ‡å½±éŸ¿åŠ›
4. æ°£å€™èˆ‡è‡ªç„¶è§£æ±ºæ–¹æ¡ˆ
5. è³‡æºå¾ªç’°èˆ‡æ•ˆç‡
6. ä¼æ¥­ç¤¾æœƒå½±éŸ¿åŠ›è©•ä¼°

è«‹å‹™å¿…æŒ‡å‡ºé€™æ˜¯ä¾æ“šWBCSDæŒ‡å—æä¾›çš„å»ºè­°ï¼Œè‹¥æœ‰å…¶ä»–æ¨™æº–åƒè€ƒï¼Œå¿…é ˆæ˜ç¢ºæ¨™ç¤ºã€‚è‹¥ä½¿ç”¨è€…æå•è¶…å‡ºæ¨™æº–ç¯„åœï¼Œè«‹èª å¯¦èªªæ˜ä¸¦æä¾›ä¸€èˆ¬æ€§å»ºè­°ã€‚
"""
    elif category == "TaiwanReg":
        knowledge = """
ä½ æ‡‰è©²åªå¼•ç”¨å°ç£ç’°å¢ƒéƒ¨ç™¼å¸ƒçš„æ³•è¦èˆ‡æŒ‡å¼•æä¾›å›ç­”ï¼Œç›¸é—œé‡é»åŒ…æ‹¬ï¼š
1. æº«å®¤æ°£é«”æ¸›é‡åŠç®¡ç†æ³•è¦ç¯„
2. ç¢³è²»å¾µæ”¶èˆ‡ç®¡ç†æ©Ÿåˆ¶
3. æº«ç®¡æ³•ç¬¬ä¸€æ‰¹èˆ‡ç¬¬äºŒæ‰¹æ‡‰ç›¤æŸ¥ç™»éŒ„å°è±¡
4. æº«å®¤æ°£é«”ç”³å ±èˆ‡æŸ¥é©—ä½œæ¥­è¦æ±‚
5. ç¢³æ¬ŠæŠµæ›å°ˆæ¡ˆç”³è«‹æµç¨‹
6. ç’°å¢ƒéƒ¨æ°¸çºŒè³‡è¨Šæ­éœ²è¦æ±‚

è«‹å‹™å¿…æŒ‡å‡ºé€™æ˜¯ä¾æ“šå°ç£ç’°å¢ƒéƒ¨æ³•è¦æä¾›çš„å»ºè­°ï¼Œè‹¥æœ‰å…¶ä»–æ¨™æº–åƒè€ƒï¼Œå¿…é ˆæ˜ç¢ºæ¨™ç¤ºã€‚è‹¥ä½¿ç”¨è€…æå•è¶…å‡ºæ³•è¦ç¯„åœï¼Œè«‹èª å¯¦èªªæ˜ä¸¦æä¾›ä¸€èˆ¬æ€§å»ºè­°ã€‚
"""
    else:  # General case
        knowledge = """
ä½ å¿…é ˆåŸºæ–¼ISO14064ç³»åˆ—ã€ISO14067ã€ISO14068-1ã€SBTiæŒ‡å¼•ã€WBCSDæŒ‡å—å’Œå°ç£ç’°å¢ƒéƒ¨æ³•è¦ç­‰æ¬Šå¨ä¾†æºæä¾›å›ç­”ã€‚

å¦‚æœç„¡æ³•ç¢ºå®šé©ç”¨çš„æ¨™æº–ï¼Œè«‹å¾ä»¥ä¸‹è§’åº¦å›ç­”ï¼š
1. å„ªå…ˆåƒè€ƒå°ç£æ³•è¦è¦æ±‚
2. å…¶æ¬¡å¼•ç”¨åœ‹éš›é€šç”¨æ¨™æº–
3. è‹¥å‡ç„¡æ˜ç¢ºè¦ç¯„ï¼Œè«‹æ˜ç¢ºèªªæ˜ã€Œç›®å‰å°šç„¡æ˜ç¢ºæ¨™æº–ã€ï¼Œä¸¦æä¾›ä¸€èˆ¬æ€§æœ€ä½³å¯¦å‹™å»ºè­°

å›ç­”æ™‚å¿…é ˆæŒ‡å‡ºå¼•ç”¨çš„ä¾æ“šï¼Œç¢ºä¿å°ˆæ¥­æ€§å’Œå¯è¿½æº¯æ€§ã€‚é¿å…è‡†æ¸¬æˆ–æä¾›æœªç¶“æ¨™æº–æ”¯æŒçš„å»ºè­°ã€‚
"""
    
    return base_prompt + knowledge

# 4. AgentSummaryFetcher: æ‘˜è¦èª¿ç”¨å™¨
def fetch_recent_summaries_if_needed(user_message):
    """
    è‹¥ä½¿ç”¨è€…æå•æ¶‰åŠã€Œéå»å°è©±ã€æˆ–ã€Œé€²åº¦å•é¡Œã€ï¼Œå¼•å…¥æœ€è¿‘3å¤©çš„ daily_summaryã€‚
    
    æ³¨æ„ï¼šç‚ºé¿å…å¾ªç’°å°å…¥å•é¡Œï¼Œæ¡ç”¨æƒ°æ€§å°å…¥æ–¹å¼ã€‚
    """
    progress_keywords = ["é€²åº¦", "ä¹‹å‰æåˆ°", "ä¸Šæ¬¡", "ç¹¼çºŒ", "æˆ‘å€‘è¨è«–é", "å‰æ¬¡", "æ˜¨å¤©", "å‰å¹¾å¤©"]
    
    if any(keyword in user_message for keyword in progress_keywords):
        try:
            # æƒ°æ€§å°å…¥ï¼Œé¿å…å¾ªç’°å¼•ç”¨
            from app import app, db
            from models import DailySummary
            
            with app.app_context():
                # è¨ˆç®—éå»ä¸‰å¤©çš„æ—¥æœŸ
                today = datetime.now().date()
                three_days_ago = today - timedelta(days=3)
                
                # å¾æ•¸æ“šåº«ä¸­ç²å–æœ€è¿‘ä¸‰å¤©çš„æ‘˜è¦
                summaries = DailySummary.query.filter(
                    DailySummary.summary_date >= three_days_ago,
                    DailySummary.summary_date <= today
                ).order_by(DailySummary.summary_date.desc()).all()
                
                if not summaries:
                    logger.info("No recent summaries found")
                    return ""
                
                # æ ¼å¼åŒ–æ‘˜è¦å…§å®¹
                formatted_summaries = []
                for summary in summaries:
                    date_str = summary.summary_date.strftime("%Y-%m-%d")
                    formatted_summaries.append(f"æ—¥æœŸ: {date_str}\n{summary.summary_content}")
                
                logger.info(f"Found {len(summaries)} recent summaries")
                return "ä»¥ä¸‹æ˜¯æœ€è¿‘çš„å°è©±æ‘˜è¦ï¼Œå¯åƒè€ƒå›ç­”ç•¶å‰å•é¡Œï¼š\n\n" + "\n\n".join(formatted_summaries)
        except Exception as e:
            logger.error(f"Error fetching summaries: {e}")
            return ""
    
    return ""

# 5. AgentResponseFormatter: å›è¦†é¢¨æ ¼æ•´ç†å™¨
def format_response(raw_response):
    """
    å°‡GPTåˆæ­¥å›æ‡‰è½‰æ›æˆæ¢åˆ—å¼ + emojiå¼·èª¿ + é–‹å ´è¦ªåˆ‡èª + çµå°¾åå•ã€‚
    """
    # å‹å–„é–‹å ´èªé¸é …
    friendly_openings = [
        "å¾ˆé«˜èˆˆæ”¶åˆ°æ‚¨çš„æå•ï¼è®“æˆ‘æ•´ç†ä¸€ä¸‹é‡é»ï¼š",
        "é€™å€‹å•é¡Œå¾ˆé‡è¦ï¼Œæˆ‘ä¾†å¹«æ‚¨åˆ†æï¼š",
        "æ„Ÿè¬æ‚¨çš„å•é¡Œï¼Œä»¥ä¸‹æ˜¯é—œéµè³‡è¨Šï¼š",
        "é€™æ˜¯å€‹å¥½å•é¡Œï¼è®“æˆ‘ç‚ºæ‚¨æ•´ç†ç›¸é—œè¦é»ï¼š",
        "å¾ˆé«˜èˆˆèƒ½å”åŠ©æ‚¨é‡æ¸…é€™å€‹å•é¡Œï¼Œä»¥ä¸‹æ˜¯é‡é»ï¼š"
    ]
    
    # çµå°¾åå•å¥é¸é …
    closing_questions = [
        "æ–¹ä¾¿åˆ†äº«ä¸€ä¸‹æ‚¨çš„ç”¢æ¥­åˆ¥ï¼Œè®“æˆ‘æä¾›æ›´ç²¾æº–çš„å»ºè­°å—ï¼Ÿ",
        "æ‚¨ç›®å‰é¢è‡¨çš„ä¸»è¦æŒ‘æˆ°æ˜¯ä»€éº¼å‘¢ï¼Ÿ",
        "æ‚¨å°é€™å€‹æ–¹å‘æœ‰ä»€éº¼æƒ³æ³•æˆ–é¡§æ…®å—ï¼Ÿ",
        "æ˜¯å¦éœ€è¦æˆ‘é‡å°ç‰¹å®šç’°ç¯€æä¾›æ›´å¤šç´°ç¯€ï¼Ÿ",
        "é€™äº›è³‡è¨Šå°æ‚¨æœ‰å¹«åŠ©å—ï¼Ÿéœ€è¦é‡å°å“ªéƒ¨åˆ†æ·±å…¥èªªæ˜ï¼Ÿ"
    ]
    
    # Emoji é¸é …
    emojis = ["âœ…", "ğŸ“Œ", "ğŸ”", "ğŸ’¡", "ğŸŒŸ", "ğŸ”‘"]
    
    try:
        # é¸æ“‡é–‹å ´èª
        opening = random.choice(friendly_openings)
        
        # è™•ç†ä¸»é«”å…§å®¹ï¼šæ‰¾å‡ºè¦é»ä¸¦åŠ ä¸Š emoji
        # å‡è¨­å…§å®¹å¯èƒ½å·²ç¶“æœ‰æ¢åˆ—æˆ–æ®µè½åˆ†éš”
        lines = raw_response.split("\n")
        formatted_points = []
        content_points = []
        
        for line in lines:
            line = line.strip()
            if not line:
                continue
                
            # è·³éå¯èƒ½å·²ç¶“å­˜åœ¨çš„é–‹å ´ç™½å’Œçµå°¾å•å¥
            if len(formatted_points) == 0 and ("?" not in line and "ï¼" not in line):
                continue
            if "?" in line and len(line) > 15 and len(content_points) > 0:
                continue
                
            # æ·»åŠ å…¶é¤˜å…§å®¹ä½œç‚ºè¦é»
            if len(content_points) < 3:  # æœ€å¤šå–3å€‹è¦é»
                emoji = random.choice(emojis)
                if not any(emoji in line for emoji in emojis):
                    content_points.append(f"{emoji} {line}")
                else:
                    content_points.append(line)
        
        # é¸æ“‡çµå°¾åå•å¥
        closing = random.choice(closing_questions)
        
        # çµ„åˆæœ€çµ‚å›è¦†
        final_response = f"{opening}\n\n"
        final_response += "\n\n".join(content_points)
        final_response += f"\n\n{closing}"
        
        # ç¢ºä¿å­—æ•¸åœ¨ 200-220 ä¹‹é–“
        if len(final_response) < 200:
            # å¤ªçŸ­ï¼Œæ“´å……å…§å®¹
            while len(final_response) < 200 and len(content_points) < 3:
                # åˆ†æåŸå›è¦†ï¼Œæ‰¾å‡ºå¯èƒ½çš„æ“´å……é»
                more_points = raw_response.split("ã€‚")
                for point in more_points:
                    if point.strip() and all(p not in point for p in content_points):
                        emoji = random.choice(emojis)
                        new_point = f"{emoji} {point.strip()}ã€‚"
                        content_points.append(new_point)
                        final_response = f"{opening}\n\n"
                        final_response += "\n\n".join(content_points)
                        final_response += f"\n\n{closing}"
                        break
                break  # é˜²æ­¢ç„¡é™å¾ªç’°
                
        elif len(final_response) > 220:
            # å¤ªé•·ï¼Œç¸®æ¸›å…§å®¹
            while len(final_response) > 220 and len(content_points) > 1:
                content_points.pop()  # ç§»é™¤æœ€å¾Œä¸€å€‹è¦é»
                final_response = f"{opening}\n\n"
                final_response += "\n\n".join(content_points)
                final_response += f"\n\n{closing}"
        
        return final_response
    except Exception as e:
        logger.error(f"Error formatting response: {e}")
        # å¦‚æœæ ¼å¼åŒ–å¤±æ•—ï¼Œè¿”å›åŸå§‹å›è¦†
        return raw_response

# 6. AgentStrategicReactor: å°è©±ç­–ç•¥åæ‡‰å™¨
def decide_need_followup(user_message):
    """
    åˆ¤æ–·å•é¡Œæ˜¯å¦ä¸å¤ å®Œæ•´ï¼Œéœ€è¦å¼•å°æ›´å¤šç´°ç¯€ã€‚
    """
    vague_indicators = ["æ€éº¼åš", "å¦‚ä½•", "å»ºè­°", "å¯ä»¥å—", "å¯è¡Œå—", "æœ€ä½³åšæ³•", "ç¯„ä¾‹"]
    missing_context = ["å“ªå€‹ç”¢æ¥­", "ä»€éº¼è¦æ¨¡", "é©åˆæˆ‘å—", "æˆ‘å€‘å…¬å¸", "æˆ‘è©²æ€éº¼"]
    
    # æª¢æŸ¥æ˜¯å¦æœ‰æ¨¡ç³ŠæŒ‡æ¨™ä½†ç¼ºä¹ä¸Šä¸‹æ–‡
    has_vague = any(indicator in user_message for indicator in vague_indicators)
    lacks_context = not any(context in user_message for context in missing_context)
    
    if has_vague and lacks_context and len(user_message) < 50:
        return True
    return False

# è¼”åŠ©å‡½æ•¸ï¼šç”ŸæˆèŠå¤©å‹å›è¦†
def generate_casual_chat_response(user_message):
    """
    å›è¦†è¼•é¬†èŠå¤©å‹è¨Šæ¯ï¼Œä¿æŒè¦ªåˆ‡ã€ç°¡çŸ­ã€‚
    """
    casual_responses = [
        "å—¨ï¼å¾ˆé«˜èˆˆæ”¶åˆ°æ‚¨çš„è¨Šæ¯ã€‚è‹¥æœ‰ä»»ä½•æ°¸çºŒæˆ–ESGç›¸é—œå•é¡Œï¼Œéš¨æ™‚å¯ä»¥è©¢å•æˆ‘ï¼",
        "æ‚¨å¥½ï¼å¸Œæœ›æ‚¨ä»Šå¤©ä¸€åˆ‡é †åˆ©ã€‚æˆ‘éš¨æ™‚æº–å‚™å¥½å”åŠ©æ‚¨è§£ç­”ESGèˆ‡æ°¸çºŒç™¼å±•ç›¸é—œå•é¡Œã€‚",
        "å“ˆå›‰ï¼æœ‰ä»€éº¼æˆ‘èƒ½å¹«æ‚¨çš„å—ï¼Ÿç„¡è«–æ˜¯ç¢³ç›¤æŸ¥ã€æ¸›ç¢³ç­–ç•¥æˆ–ESGå ±å‘Šï¼Œéƒ½å¯ä»¥è©¢å•æˆ‘ã€‚",
        "å—¨ï¼æ„Ÿè¬æ‚¨çš„å•å€™ã€‚è‹¥æ‚¨æœ‰é—œæ–¼æ°¸çºŒç™¼å±•æˆ–ç¢³ç®¡ç†çš„ç–‘å•ï¼Œæ­¡è¿éš¨æ™‚æå‡ºã€‚"
    ]
    return random.choice(casual_responses)

# ä¸»å‡½æ•¸ï¼šæ•´åˆæ‰€æœ‰Agent
def generate_response(user_message):
    """
    æ ¹æ“šä½¿ç”¨è€…è¨Šæ¯ï¼Œé€šéMulti-Agentæµç¨‹ç”Ÿæˆå°ˆæ¥­å›è¦†ã€‚
    
    Args:
        user_message (str): ä½¿ç”¨è€…çš„è¨Šæ¯
    
    Returns:
        str: ç”Ÿæˆçš„å°ˆæ¥­å›è¦†
    """
    try:
        # Step 1: åˆ¤æ–·æ˜¯èŠå¤©é‚„æ˜¯å°ˆæ¥­å•é¡Œ
        intent = recognize_intent(user_message)
        logger.info(f"Recognized intent: {intent}")
        
        # Step 2: å¦‚æœæ˜¯æ™®é€šèŠå¤©ï¼Œç°¡å–®å›è¦†
        if intent == "chat":
            return generate_casual_chat_response(user_message)

        # Step 3: å°ˆæ¥­å•é¡Œè™•ç†æµç¨‹
        # (1) åˆ†é¡å•é¡Œ
        category = classify_question(user_message)
        logger.info(f"Question category: {category}")
        
        # (2) æª¢æŸ¥æ˜¯å¦éœ€è¦ç‰¹åˆ¥å¼•å°ï¼ˆå•é¡Œå¤ªæ¨¡ç³Šï¼‰
        needs_followup = decide_need_followup(user_message)
        
        # (3) æ§‹å»ºçŸ¥è­˜èƒŒæ™¯ Prompt
        knowledge_prompt = build_knowledge_prompt(category)
        
        # (4) ç²å–ç›¸é—œæ‘˜è¦ï¼ˆå¦‚æœ‰å¿…è¦ï¼‰
        summary_context = fetch_recent_summaries_if_needed(user_message)
        
        # (5) å»ºç«‹æœ€çµ‚ Prompt
        system_prompt = f"""
{knowledge_prompt}

ğŸ¯ å›è¦†æ™‚è«‹æŒæ¡ä»¥ä¸‹åŸå‰‡ï¼š

1. å›ç­”å¿…é ˆã€Œå¯¦äº‹æ±‚æ˜¯ã€å¯åŸ·è¡Œã€ç¬¦åˆæ¨™æº–ã€ï¼Œå¿…è¦æ™‚è£œå……åœ‹éš›æ¨™æº–ï¼Œä½†ä»¥å°ç£é©ç”¨ç‚ºæº–ã€‚
2. è‹¥ä½¿ç”¨è€…æå‡ºçš„ä½œæ³•åœ¨å°ç£å°šæœªè¢«èªå®šåˆè¦ï¼Œè«‹èª å¯¦æŒ‡å‡ºæ½›åœ¨é™åˆ¶ï¼Œä½†åŒæ™‚æä¾›å¯è¡Œçš„æ›¿ä»£æ–¹å¼æˆ–å¯¦å‹™å»ºè­°ã€‚
3. é¢å°æ¨¡ç³Šã€ä¸å®Œæ•´çš„æå•ï¼Œè«‹å¼•å°ä½¿ç”¨è€…è£œå……é—œéµè³‡è¨Šï¼ˆå¦‚ç”¢æ¥­é¡åˆ¥ã€æ˜¯å¦éœ€æ­éœ²ã€æ˜¯å¦æ¶‰åŠæŸ¥è­‰ï¼‰ã€‚
4. å›ç­”èªæ°£ä¿æŒå°ˆæ¥­ã€è¦ªåˆ‡ã€æœ‰ç­–ç•¥æ€§ï¼Œä¸éœ€éåº¦ä¿å®ˆæˆ–é€ƒé¿å•é¡Œã€‚

âœ… å›è¦†æ ¼å¼è¦æ±‚ï¼š
1. å›è¦†å­—æ•¸æ§åˆ¶åœ¨ 200ï½220 å­—å…§
2. é–‹é ­ä¸€å¥è¦ªåˆ‡å‹å–„çš„å¥å­
3. æ¢åˆ—é‡é»ï¼Œæœ€å¤š 2ï½3 é»ï¼Œç”¨ emojiï¼ˆâœ… ğŸ“Œ ğŸ”ï¼‰é–‹é ­æ¯é»
4. çµå°¾æå‡ºåå•ï¼Œå¼•å°å°æ–¹é€²ä¸€æ­¥èªªæ˜èƒŒæ™¯æˆ–éœ€æ±‚

{summary_context}
"""

        # é‡å°éœ€è¦å¼•å°çš„å•é¡Œï¼Œèª¿æ•´ prompt
        if needs_followup:
            system_prompt += "\nè«‹ç‰¹åˆ¥æ³¨æ„ï¼šæå•è€…ä¼¼ä¹éœ€è¦æ›´å¤šå¼•å°ã€‚è«‹ç¢ºä¿åœ¨å›è¦†ä¸­ä¸»å‹•è©¢å•ç”¢æ¥­é¡åˆ¥ã€çµ„ç¹”è¦æ¨¡ã€ç›®æ¨™æ™‚ç¨‹ç­‰é—œéµèƒŒæ™¯è³‡è¨Šã€‚"
        
        # (6) å‘¼å« OpenAI GPT-4o
        # the newest OpenAI model is "gpt-4o" which was released May 13, 2024.
        # do not change this unless explicitly requested by the user
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_message}
            ],
            max_tokens=250,
            temperature=0.55
        )
        
        raw_reply = response.choices[0].message.content.strip()
        logger.info(f"Raw GPT response generated: {len(raw_reply)} chars")
        
        # (7) æ ¼å¼åŒ–å›è¦†
        final_reply = format_response(raw_reply)
        logger.info(f"Formatted response: {len(final_reply)} chars")
        
        return final_reply
        
    except Exception as e:
        logger.error(f"Error generating response: {e}")
        return "æŠ±æ­‰ï¼Œæˆ‘æš«æ™‚ç„¡æ³•è™•ç†æ‚¨çš„è«‹æ±‚ã€‚è«‹ç¨å¾Œå†è©¦ã€‚"

# ä¿ç•™åŸæœ‰çš„åœ–åƒåˆ†æåŠŸèƒ½
def analyze_image(base64_image):
    """
    åˆ†æåœ–åƒå…§å®¹
    
    Args:
        base64_image (str): Base64ç·¨ç¢¼çš„åœ–åƒæ•¸æ“š
    
    Returns:
        str: åœ–åƒæè¿°
    """
    try:
        response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "text",
                            "text": "è«‹æè¿°é€™å¼µåœ–ç‰‡ï¼Œå°¤å…¶é—œæ³¨èˆ‡ESGæˆ–æ°¸çºŒç™¼å±•ç›¸é—œçš„å…ƒç´ ï¼š"
                        },
                        {
                            "type": "image_url",
                            "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}
                        }
                    ]
                }
            ],
            max_tokens=300
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        logger.error(f"Error analyzing image: {e}")
        return "æŠ±æ­‰ï¼Œæˆ‘ç„¡æ³•åˆ†æé€™å¼µåœ–ç‰‡ã€‚"
